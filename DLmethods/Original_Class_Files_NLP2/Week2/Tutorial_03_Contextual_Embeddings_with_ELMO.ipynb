{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tutorial_03_Contextual_Embeddings_with_ELMO.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2yTosTQy3ync"},"source":["# Tutorial 3 - ELMO: Deep Contextualized Word Representations\n","\n","<img src=\"https://live.staticflickr.com/3545/3508966591_9dc9cbe3f5_b.jpg\">\n","\n","Word Embeddings are very useful in preparing meaningful representation of textual data in vector space. Authors Peters et.al. in their work titled [\"Deep contextualized word representations\"](https://arxiv.org/pdf/1802.05365.pdf) present a deep bidirectional language model which models:\n","1. complex characteristics of word use (e.g., syntax and semantics)\n","2. how these uses vary across linguistic contexts (i.e., to model\n","polysemy)\n","\n","\n","The ELMO model uses vectors derived from a bidirectional LSTMs that are trained with a coupled language model(LM) objective on a large text corpus hence the name __ELMo or (Embeddings from Language Models)__ representations\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1xXYnD-eYq-P","executionInfo":{"status":"ok","timestamp":1626971040870,"user_tz":420,"elapsed":23,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"1f9fb6fc-8a63-4dfc-b3c9-3096863e8c39"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu Jul 22 16:24:00 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oKgXcSHt7d7b"},"source":["### Load Dependencies"]},{"cell_type":"code","metadata":{"id":"L9xltnc67AfY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626971762052,"user_tz":420,"elapsed":4445,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"9466d867-29c4-450c-afa7-a09028f54bb8"},"source":["!pip install chart-studio"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting chart-studio\n","  Downloading chart_studio-1.1.0-py3-none-any.whl (64 kB)\n","\u001b[?25l\r\u001b[K     |█████                           | 10 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from chart-studio) (2.23.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from chart-studio) (4.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from chart-studio) (1.15.0)\n","Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from chart-studio) (1.3.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->chart-studio) (3.0.4)\n","Installing collected packages: chart-studio\n","Successfully installed chart-studio-1.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A45Yg782085m","executionInfo":{"status":"ok","timestamp":1626971767272,"user_tz":420,"elapsed":3234,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from sklearn import preprocessing\n","\n","from IPython.display import HTML\n","import logging\n","logging.getLogger('tensorflow').disabled = True"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"SQLRvb4H7IKh","executionInfo":{"status":"ok","timestamp":1626971768784,"user_tz":420,"elapsed":1136,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"eb7b1f38-7f97-4f94-e3dd-2cdda4e22445"},"source":["import chart_studio.plotly as py\n","import plotly.graph_objs as go\n","from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n","\n","init_notebook_mode(connected=True)"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/html":["        <script type=\"text/javascript\">\n","        window.PlotlyConfig = {MathJaxConfig: 'local'};\n","        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n","        if (typeof require !== 'undefined') {\n","        require.undef(\"plotly\");\n","        requirejs.config({\n","            paths: {\n","                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n","            }\n","        });\n","        require(['plotly'], function(Plotly) {\n","            window._Plotly = Plotly;\n","        });\n","        }\n","        </script>\n","        "]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"mhXMtkGt39C7"},"source":["## TensorFlow-Hub\n","\n","__TensorFlow Hub__ is a repository for machine learning models.\n","From image classification, text embeddings, audio, and video action recognition, TensorFlow Hub is a space where you can browse trained models and datasets from across the TensorFlow ecosystem. \n","\n","\n","Loading ELMO pretrained model using TF-Hub is as simple as mentioning the endpoint/URL of the model of interest. In this case, we will be using _version 3_ of the model"]},{"cell_type":"code","metadata":{"id":"UddeIWwa38sK","executionInfo":{"status":"ok","timestamp":1626971780176,"user_tz":420,"elapsed":9081,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["url = \"https://tfhub.dev/google/elmo/3\"\n","embed = hub.load(url)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"O9mLALsgDR-b","executionInfo":{"status":"ok","timestamp":1626971832284,"user_tz":420,"elapsed":131,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["# elmo = hub.Module(\"https://tfhub.dev/google/elmo/3\", trainable=True)\n","# embeddings = elmo(\n","#     [\"the cat is on the mat\", \"dogs are in the fog\"],\n","#     signature=\"default\",\n","#     as_dict=True)[\"elmo\"]\n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NgenZzxD4wdM"},"source":["## Contextual Vectors\n","\n","\n","Techniques such as Word2Vec, Glove, FastText, etc covered so far are great at preparing dense vector representations of a given word. Yet, there are difficulties when it comes to capturing the meaning of same word in different contexts (_word sense disambiguation_). \n","\n","No matter how many senses a word has, word embedding methods would generate the same vector representation. This can lead to problems for downstream NLP tasks.\n","\n","For instance, let us talk about the word __bank__. The word bank can refer to a financial institution, can be used as an adjective or even to point towards a location (slope land besides a water body like river).\n","\n","Unless a model understands different meanings of the word __bank__, it may mis-classify a sentence related to financial instituitions into a class of sentences refering to river banks.\n","\n","Let us understand this better with the help of an example"]},{"cell_type":"code","metadata":{"id":"7xwERy9F36_8","executionInfo":{"status":"ok","timestamp":1626971853201,"user_tz":420,"elapsed":138,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["# sample dataset\n","word = 'bank'\n","wsd_bank = [\n","            'The river bank is an amazing place',\n","            'I have deposited my money at the bank',\n","            'Did you withdraw money from the bank',\n","            'We walked along the river bank',\n","            'My wife and I have a joint bank account',\n","            'She is a dependable person and you can bank upon her'\n","            ]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H9UzsWz80giU","executionInfo":{"status":"ok","timestamp":1626971873374,"user_tz":420,"elapsed":147,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"6eae9b59-fdd2-49e1-85dc-dc4ba9b0d773"},"source":["# identify the position of the word of interest across the corpus\n","idx_of_interest = []\n","idx = 0\n","for s in wsd_bank:\n","  for w in s.split():\n","    if w.lower() in [word, word + 's', word + 'ing', word + 'ed', word + 'er']:\n","      idx_of_interest.append(idx)\n","    idx += 1\n","\n","idx_of_interest"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 14, 21, 27, 35, 45]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C3wKyqGdZHQ6","executionInfo":{"status":"ok","timestamp":1626971972692,"user_tz":420,"elapsed":187,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"bfba2b7c-281a-48c5-98bb-52c500ce3313"},"source":["# transform corpus into tensors\n","tokens_input = [s.split() for s in wsd_bank]\n","tokens_input"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['The', 'river', 'bank', 'is', 'an', 'amazing', 'place'],\n"," ['I', 'have', 'deposited', 'my', 'money', 'at', 'the', 'bank'],\n"," ['Did', 'you', 'withdraw', 'money', 'from', 'the', 'bank'],\n"," ['We', 'walked', 'along', 'the', 'river', 'bank'],\n"," ['My', 'wife', 'and', 'I', 'have', 'a', 'joint', 'bank', 'account'],\n"," ['She',\n","  'is',\n","  'a',\n","  'dependable',\n","  'person',\n","  'and',\n","  'you',\n","  'can',\n","  'bank',\n","  'upon',\n","  'her']]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EnCYN4OhZKy1","executionInfo":{"status":"ok","timestamp":1626972041745,"user_tz":420,"elapsed":177,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"b41fa28d-1837-4a49-f382-5511c43d1093"},"source":["tokens_length = [len(s.split()) for s in wsd_bank]\n","tokens_length"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[7, 8, 7, 6, 9, 11]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"woluPr2JZPbd","executionInfo":{"status":"ok","timestamp":1626972128922,"user_tz":420,"elapsed":200,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"cbc7eb8e-b1e3-4459-d183-46b8ed20defd"},"source":["# transform each sentence into a tensors of different lengths (ragged tensors)\n","sentences = tf.constant(wsd_bank)\n","sentences"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(6,), dtype=string, numpy=\n","array([b'The river bank is an amazing place',\n","       b'I have deposited my money at the bank',\n","       b'Did you withdraw money from the bank',\n","       b'We walked along the river bank',\n","       b'My wife and I have a joint bank account',\n","       b'She is a dependable person and you can bank upon her'],\n","      dtype=object)>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g38XueIeZSvO","executionInfo":{"status":"ok","timestamp":1626972133388,"user_tz":420,"elapsed":225,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"ca3bea13-9cfc-4988-f579-48aeb1f947e0"},"source":["words = tf.strings.split(sentences, ' ')\n","words"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.RaggedTensor [[b'The', b'river', b'bank', b'is', b'an', b'amazing', b'place'], [b'I', b'have', b'deposited', b'my', b'money', b'at', b'the', b'bank'], [b'Did', b'you', b'withdraw', b'money', b'from', b'the', b'bank'], [b'We', b'walked', b'along', b'the', b'river', b'bank'], [b'My', b'wife', b'and', b'I', b'have', b'a', b'joint', b'bank', b'account'], [b'She', b'is', b'a', b'dependable', b'person', b'and', b'you', b'can', b'bank', b'upon', b'her']]>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JeKOe-baj_u","executionInfo":{"status":"ok","timestamp":1626972285988,"user_tz":420,"elapsed":173,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"0a607950-90a1-4f19-827b-387d61fa5d58"},"source":["# standardize the size and transform ragged tensors to fixed length tensors\n","tokens = words.to_tensor(default_value='', \n","                         shape=[None, max(tokens_length)])\n","tokens"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(6, 11), dtype=string, numpy=\n","array([[b'The', b'river', b'bank', b'is', b'an', b'amazing', b'place',\n","        b'', b'', b'', b''],\n","       [b'I', b'have', b'deposited', b'my', b'money', b'at', b'the',\n","        b'bank', b'', b'', b''],\n","       [b'Did', b'you', b'withdraw', b'money', b'from', b'the', b'bank',\n","        b'', b'', b'', b''],\n","       [b'We', b'walked', b'along', b'the', b'river', b'bank', b'', b'',\n","        b'', b'', b''],\n","       [b'My', b'wife', b'and', b'I', b'have', b'a', b'joint', b'bank',\n","        b'account', b'', b''],\n","       [b'She', b'is', b'a', b'dependable', b'person', b'and', b'you',\n","        b'can', b'bank', b'upon', b'her']], dtype=object)>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"ATgmYrWb800Q"},"source":["### ELMO Embeddings\n","\n","The ELMO model exposes three different types of embeddings. These depend upon the layer which is being used for inference. \n","\n","![](https://i.imgur.com/zNe5Ydx.png)\n","\n","[Source](http://jalammar.github.io/illustrated-bert/)\n","\n","![](https://i.imgur.com/E65GAvp.png)\n","\n","From the TF-Hub documentation, we have the following output options available:\n","+ __word_emb__: the character-based word representations with shape [batch_size, max_length, 512].\n","+ __lstm_outputs1__: the first LSTM hidden state with shape [batch_size, max_length, 1024].\n","+ __lstm_outputs2__: the second LSTM hidden state with shape [batch_size, max_length, 1024].\n","+ __elmo__: the weighted sum of the 3 layers, where the weights are trainable. This tensor has shape [batch_size, max_length, 1024]\n","+ __default__: a fixed mean-pooling of all contextualized word representations with shape [batch_size, 1024].\n","\n","For this section, as we are interested in understanding how the model understands and builds different embeddings of the same word used in different contexts, we will make use of __lstm_outputs1__.\n","\n","You can experiment with other layers as well and note the difference in behaviour"]},{"cell_type":"code","metadata":{"id":"VC3g_PAL3666","executionInfo":{"status":"ok","timestamp":1626973259096,"user_tz":420,"elapsed":1004,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["# get embeddings\n","outputs = embed.signatures[\"tokens\"](tokens=tokens,\n","                                     sequence_len=tf.constant(tokens_length))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"oWFRTBdTazSk"},"source":["outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xeYw8H96xudt","executionInfo":{"status":"ok","timestamp":1626973122468,"user_tz":420,"elapsed":185,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["# flatten the output tensor\n","elmo_vectors = [j.numpy() for i in outputs['lstm_outputs1'] \\\n","                            for j in i  \\\n","                              if ~np.all((j.numpy() == 0))]"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QgWra1I0_Oyo","executionInfo":{"status":"ok","timestamp":1626973210940,"user_tz":420,"elapsed":163,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"e1c433f9-261c-4157-e4db-6515f6a9e5da"},"source":["len(elmo_vectors)"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["48"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sDW4xqrY_Ymo","executionInfo":{"status":"ok","timestamp":1626973213108,"user_tz":420,"elapsed":128,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"1b1a7eac-a069-4489-855c-a1e26c38aff6"},"source":["elmo_vectors[0].shape"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1024,)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"i90ntjB_65J8"},"source":["## Visualize the Embeddings\n","\n","We have the embeddings for each of the words in our sample corpus. Let us now visualize the contextual embeddings to understand how ELMO picks up on the context of any given word.\n","\n","Note that in this sample setup, our word of interest is __bank__ and its usage in different contexts.\n","\n","We will perform the following steps to visualize the contextual embeddings:\n","\n","+ __Dimensionality Reduction__ : ELMO transforms each word is transformed into a $1024$ dimensional contextual embedding vector. To visualize such a large vector, we first transform it into managiable 2D setup using __Principal Component Analysis (PCA)__\n","+ __Scatter Plot__ : We plot each usage of the _word of interest_ on the scatter plot and label/annotate each data point with the sentence where the word was used."]},{"cell_type":"code","metadata":{"id":"1xHCfPvs363_","executionInfo":{"status":"ok","timestamp":1626973289952,"user_tz":420,"elapsed":344,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["from sklearn.decomposition import PCA\n","\n","pca = PCA(n_components=2)\n","pca_output = pca.fit_transform(elmo_vectors)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"GJnQdEEZ7D6T","executionInfo":{"status":"ok","timestamp":1626973365294,"user_tz":420,"elapsed":387,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"51d7a7be-60ea-4b07-cfa0-7ea27ca08e91"},"source":["data = [\n","    go.Scatter(\n","        x=[i[0] for idx,i in enumerate(pca_output) if idx in idx_of_interest],\n","        y=[i[1] for idx,i in enumerate(pca_output) if idx in idx_of_interest],\n","        mode='markers+text',\n","        textposition=\"bottom center\",\n","        text=[i for i in wsd_bank],\n","    marker=dict(\n","        size=16,\n","        color = [i for i in idx_of_interest], #set color equal to a variable\n","        opacity= 0.8,\n","        colorscale='sunset',\n","        showscale=False\n","    )\n","    )\n","]\n","layout = go.Layout()\n","layout = dict(\n","              yaxis = dict(zeroline = True),\n","              xaxis = dict(zeroline = True),\n","             )\n","fig = go.Figure(data=data, layout=layout)\n","fig.show(renderer=\"colab\")"],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"daecc66a-6b8b-4b51-be1c-35016bb01635\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"daecc66a-6b8b-4b51-be1c-35016bb01635\")) {\n","                    Plotly.newPlot(\n","                        'daecc66a-6b8b-4b51-be1c-35016bb01635',\n","                        [{\"marker\": {\"color\": [2, 14, 21, 27, 35, 45], \"colorscale\": [[0.0, \"rgb(243, 231, 155)\"], [0.16666666666666666, \"rgb(250, 196, 132)\"], [0.3333333333333333, \"rgb(248, 160, 126)\"], [0.5, \"rgb(235, 127, 134)\"], [0.6666666666666666, \"rgb(206, 102, 147)\"], [0.8333333333333334, \"rgb(160, 89, 160)\"], [1.0, \"rgb(92, 83, 165)\"]], \"opacity\": 0.8, \"showscale\": false, \"size\": 16}, \"mode\": \"markers+text\", \"text\": [\"The river bank is an amazing place\", \"I have deposited my money at the bank\", \"Did you withdraw money from the bank\", \"We walked along the river bank\", \"My wife and I have a joint bank account\", \"She is a dependable person and you can bank upon her\"], \"textposition\": \"bottom center\", \"type\": \"scatter\", \"x\": [7.303633408219346, 7.182394523916736, 7.443361383501699, 6.844079639345841, 7.93071368180655, 5.400230182359555], \"y\": [1.9151130598883752, -1.1862592726172612, -2.159329989478313, 0.8735468428920532, -1.298872533674056, -2.3251780694252244]}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"zeroline\": true}, \"yaxis\": {\"zeroline\": true}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('daecc66a-6b8b-4b51-be1c-35016bb01635');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"NuvP1Ayj4aCq"},"source":["This is pretty interesting. As you can see in the above plot, our sample corpus had 6 sentences containing the word __bank__ in different contexts. The contexts where the meaning is similar, the vectors are placed nearby as compared to contexts where the word refers to something entirely different.\n","\n","The vectors where the word _bank_ is used in context of a __financial instituition__ are placed nearby as compared to its usage in context of __location__(river bank) or as an __adjective__ (bankable/dependable person)"]},{"cell_type":"markdown","metadata":{"id":"eikU5VMV5Y9U"},"source":["## Application: Document clustering with Elmo Embeddings\n","\n","We have performed document clustering in previous notebooks using different embedding techniques like (FastText, Word2Vec, etc.).\n","\n","In this section, we will use ELMO embeddings to understand how it performs at a document level. \n","\n","+ Remember that ELMO provides us a direct interface to get sentence level embeddings. \n","+ This is contrast to earlier techniques where we had to perform averaging or use other methods to aggregate word level embeddings to get document/sentence level embeddings. \n","+ Also note that ELMO learns contextual embeddings hence it is imperative that the model uses the sentences/corpus as-is (without any pre-processing)"]},{"cell_type":"code","metadata":{"id":"Uzj_n0TVznsL","executionInfo":{"status":"ok","timestamp":1626973533774,"user_tz":420,"elapsed":156,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["# sample corpus\n","corpus = ['The sky is blue and beautiful.',\n","          'Love this blue and beautiful sky!',\n","          'The quick brown fox jumps over the lazy dog.',\n","          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n","          'I love green eggs, ham, sausages and bacon!',\n","          'The brown fox is quick and the blue dog is lazy!',\n","          'The sky is very blue and the sky is very beautiful today',\n","          'The dog is lazy but the brown fox is quick!'    \n","]\n","labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"CS06j_Os680F","executionInfo":{"status":"ok","timestamp":1626973546559,"user_tz":420,"elapsed":167,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["corpus = np.array(corpus)\n","corpus_df = pd.DataFrame({'Document': corpus, \n","                          'Category': labels})\n","corpus_df = corpus_df[['Document', 'Category']]"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HhW7iNET5quF","outputId":"f75632fb-85cb-43f0-d436-8ec212c58513"},"source":["# get elmo sentence embeddings\n","elmo_sent_vectors = embed.signatures[\"default\"](tf.constant(corpus))['default']\n","elmo_sent_vectors.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([8, 1024])"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288},"id":"N2x054hj6cM6","outputId":"e683901c-0e8c-4243-af07-d6e61dcb6408"},"source":["from sklearn.cluster import AffinityPropagation\n","\n","ap = AffinityPropagation()\n","ap.fit(elmo_sent_vectors.numpy())\n","\n","cluster_labels = ap.labels_\n","cluster_labels = pd.DataFrame(cluster_labels, \n","                              columns=['ClusterLabel'])\n","\n","pd.concat([corpus_df, cluster_labels], axis=1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Document</th>\n","      <th>Category</th>\n","      <th>ClusterLabel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The sky is blue and beautiful.</td>\n","      <td>weather</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Love this blue and beautiful sky!</td>\n","      <td>weather</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The quick brown fox jumps over the lazy dog.</td>\n","      <td>animals</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A king's breakfast has sausages, ham, bacon, e...</td>\n","      <td>food</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I love green eggs, ham, sausages and bacon!</td>\n","      <td>food</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>The brown fox is quick and the blue dog is lazy!</td>\n","      <td>animals</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>The sky is very blue and the sky is very beaut...</td>\n","      <td>weather</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>The dog is lazy but the brown fox is quick!</td>\n","      <td>animals</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            Document Category  ClusterLabel\n","0                     The sky is blue and beautiful.  weather             0\n","1                  Love this blue and beautiful sky!  weather             0\n","2       The quick brown fox jumps over the lazy dog.  animals             2\n","3  A king's breakfast has sausages, ham, bacon, e...     food             1\n","4        I love green eggs, ham, sausages and bacon!     food             1\n","5   The brown fox is quick and the blue dog is lazy!  animals             2\n","6  The sky is very blue and the sky is very beaut...  weather             0\n","7        The dog is lazy but the brown fox is quick!  animals             2"]},"metadata":{"tags":[]},"execution_count":22}]}]}