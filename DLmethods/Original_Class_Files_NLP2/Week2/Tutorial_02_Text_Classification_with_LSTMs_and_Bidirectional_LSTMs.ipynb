{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tutorial_02_Text_Classification_with_LSTMs_and_Bidirectional_LSTMs.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"sFvetZ-tOlmP"},"source":["# Tutorial 2 - Text Classification - Deep Learning Sequential Models - LSTMs, Stacked LSTMs and Bidirectional LSTMs\n","\n","Another new and interesting approach to supervised deep learning is the use of recurrent neural networks (RNNs) and long short-term memory networks (LSTMs) which also considers the sequence of data (words, events and so on). These are more advanced models than your regular fully connected deep networks and usually take more time to train.\n","\n","The focus of this tutorial will be to build different seuquential deep learning models on a classic sentiment analysis - text classification problem which includes the following models:\n","\n","- Long Short Term Memory Networks (LSTMs)\n","- Stacked LSTMs\n","- Bi-directional LSTMs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKJ1RzkKYl8f","executionInfo":{"status":"ok","timestamp":1626913968336,"user_tz":420,"elapsed":420,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"9219732f-046c-413d-e004-3e7b788b9cad"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Thu Jul 22 00:32:47 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y14RIcvYOYxL","executionInfo":{"status":"ok","timestamp":1626915723999,"user_tz":420,"elapsed":13777,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"beae4828-1d78-4640-ef68-06d0e34fe10f"},"source":["!pip install contractions\n","!pip install textsearch\n","!pip install tqdm\n","import nltk\n","nltk.download('punkt')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting contractions\n","  Downloading contractions-0.0.52-py2.py3-none-any.whl (7.2 kB)\n","Collecting textsearch>=0.0.21\n","  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n","Collecting pyahocorasick\n","  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n","\u001b[K     |████████████████████████████████| 321 kB 21.1 MB/s \n","\u001b[?25hCollecting anyascii\n","  Downloading anyascii-0.2.0-py3-none-any.whl (283 kB)\n","\u001b[K     |████████████████████████████████| 283 kB 15.7 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n","  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85455 sha256=feb0ff708e40dec35c34a27095ca93d743222aae4b5ebd091afa464b8dc4f0a3\n","  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n","Successfully built pyahocorasick\n","Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n","Successfully installed anyascii-0.2.0 contractions-0.0.52 pyahocorasick-1.4.2 textsearch-0.0.21\n","Requirement already satisfied: textsearch in /usr/local/lib/python3.7/dist-packages (0.0.21)\n","Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch) (0.2.0)\n","Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch) (1.4.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"Sn_ybSNzO5ER","executionInfo":{"status":"ok","timestamp":1626915734859,"user_tz":420,"elapsed":402,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["import pandas as pd\n","import numpy as np\n","\n","# fix random seed for reproducibility\n","seed = 42\n","np.random.seed(seed)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FyES71rSO7pV"},"source":["## Load Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdBD9UaJO5BZ","executionInfo":{"status":"ok","timestamp":1626915789768,"user_tz":420,"elapsed":43363,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"881d6ea6-3655-4b08-b17e-3c9820ffcdd9"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","dataset = pd.read_csv(\"/content/drive/My Drive/NLP_DeepLearning_Course/Week1/movie_reviews.csv.bz2\", compression='bz2')\n","dataset.info()\n","# dataset = pd.read_csv(r'movie_reviews.csv.bz2', compression='bz2')\n","# dataset.info()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 50000 entries, 0 to 49999\n","Data columns (total 2 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   review     50000 non-null  object\n"," 1   sentiment  50000 non-null  object\n","dtypes: object(2)\n","memory usage: 781.4+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"bPx7U1lPO4_A","executionInfo":{"status":"ok","timestamp":1626915797329,"user_tz":420,"elapsed":279,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"e18658f1-edec-4ff6-da6f-764777dfbeeb"},"source":["# take a peek at the data\n","dataset.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"B4TWC-NwPCDg"},"source":["## Prepare Train Test Splits"]},{"cell_type":"code","metadata":{"id":"u3UGyXtrO48c","executionInfo":{"status":"ok","timestamp":1626915814870,"user_tz":420,"elapsed":266,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["# build train and test datasets\n","reviews = dataset['review'].values\n","sentiments = dataset['sentiment'].values\n","\n","train_reviews = reviews[:35000]\n","train_sentiments = sentiments[:35000]\n","\n","test_reviews = reviews[35000:]\n","test_sentiments = sentiments[35000:]"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xb9swEuMPIOF"},"source":["## Text Wrangling and Normalization"]},{"cell_type":"code","metadata":{"id":"FAFqOOv5O46S","executionInfo":{"status":"ok","timestamp":1626915823011,"user_tz":420,"elapsed":534,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["import contractions\n","from bs4 import BeautifulSoup\n","import numpy as np\n","import re\n","import tqdm\n","import unicodedata\n","\n","\n","def strip_html_tags(text):\n","  soup = BeautifulSoup(text, \"html.parser\")\n","  [s.extract() for s in soup(['iframe', 'script'])]\n","  stripped_text = soup.get_text()\n","  stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n","  return stripped_text\n","\n","def remove_accented_chars(text):\n","  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n","  return text\n","\n","def pre_process_corpus(docs):\n","  norm_docs = []\n","  for doc in tqdm.tqdm(docs):\n","    doc = strip_html_tags(doc)\n","    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n","    doc = doc.lower()\n","    doc = remove_accented_chars(doc)\n","    doc = contractions.fix(doc)\n","    # lower case and remove special characters\\whitespaces\n","    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, flags=re.I|re.A)\n","    doc = re.sub(' +', ' ', doc)\n","    doc = doc.strip()  \n","    norm_docs.append(doc)\n","  \n","  return norm_docs"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3k3ykIhZO43Q","executionInfo":{"status":"ok","timestamp":1626915850957,"user_tz":420,"elapsed":23851,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"40146109-81ec-4825-bba5-8f48acd4ab41"},"source":["%%time\n","\n","norm_train_reviews = pre_process_corpus(train_reviews)\n","norm_test_reviews = pre_process_corpus(test_reviews)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["100%|██████████| 35000/35000 [00:16<00:00, 2125.34it/s]\n","100%|██████████| 15000/15000 [00:07<00:00, 2113.63it/s]"],"name":"stderr"},{"output_type":"stream","text":["CPU times: user 23.6 s, sys: 180 ms, total: 23.8 s\n","Wall time: 23.6 s\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"jhmdY6F1PRiN"},"source":["## Preprocessing\n","To prepare text data for our deep learning model, we transform each review into a sequence. Every word in the review is mapped to an integer index and thus the sentence turns into a sequence of numbers.\n","\n","To perform this transformation, ``tensorflow.keras`` provides the ``Tokenizer``"]},{"cell_type":"code","metadata":{"id":"UjUXKci_O40k","executionInfo":{"status":"ok","timestamp":1626915875962,"user_tz":420,"elapsed":7874,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["import tensorflow as tf\n","\n","t = tf.keras.preprocessing.text.Tokenizer(oov_token='<UNK>')\n","# fit the tokenizer on the documents\n","t.fit_on_texts(norm_train_reviews)\n","t.word_index['<PAD>'] = 0"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rGJXKrY8PkHp","executionInfo":{"status":"ok","timestamp":1626915885603,"user_tz":420,"elapsed":319,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"405b857a-685f-4e10-a263-792e07dc485e"},"source":["# word at max index, word at min index and index of <UNK>\n","max([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), min([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), t.word_index['<UNK>']"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(('dawgis', 175845), ('<PAD>', 0), 1)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"iM47L37HPocW","executionInfo":{"status":"ok","timestamp":1626915895446,"user_tz":420,"elapsed":6006,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["train_sequences = t.texts_to_sequences(norm_train_reviews)\n","test_sequences = t.texts_to_sequences(norm_test_reviews)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2gWeJHP-Pqat"},"source":["### Processed Dataset Summary"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ig-1HjaCPoaD","executionInfo":{"status":"ok","timestamp":1626915895448,"user_tz":420,"elapsed":29,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"7b1a9168-d422-4f12-a8ef-46de4ebcd8e0"},"source":["print(\"Vocabulary size={}\".format(len(t.word_index)))\n","print(\"Number of Documents={}\".format(t.document_count))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Vocabulary size=175846\n","Number of Documents=35000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hy5nIYW5PvDR"},"source":["## Sequence Normalization\n","\n","Not all reviews are of same length. To handle this difference in length of reviews, we define a maximum length. For reviews which are smaller than this length, we pad them with zeros which longer ones are truncated"]},{"cell_type":"code","metadata":{"id":"b1F4khDyPoXY","executionInfo":{"status":"ok","timestamp":1626916511811,"user_tz":420,"elapsed":776,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["MAX_SEQUENCE_LENGTH = 1000"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TR798dkUPoU-","executionInfo":{"status":"ok","timestamp":1626916515875,"user_tz":420,"elapsed":1805,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"afbddc35-aa71-49c4-958b-a82b302d968e"},"source":["# pad dataset to a maximum review length in words\n","X_train = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","X_test = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","X_train.shape, X_test.shape"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((35000, 1000), (15000, 1000))"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"At7eauUYP6rK"},"source":["## Encoding Labels\n","The dataset contains labels of the form positive/negative. The following step encodes the labels using ``sklearn``'s ``LabelEncoder``"]},{"cell_type":"code","metadata":{"id":"jO16tvp9PoSQ","executionInfo":{"status":"ok","timestamp":1626916776074,"user_tz":420,"elapsed":350,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["from sklearn.preprocessing import LabelEncoder\n","\n","le = LabelEncoder()\n","# positive -> 1, negative -> 0\n","num_classes=2 "],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"2BqRFaQ5QDTN","executionInfo":{"status":"ok","timestamp":1626916785135,"user_tz":420,"elapsed":252,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["y_train = le.fit_transform(train_sentiments)\n","y_test = le.transform(test_sentiments)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"-xr8OnDGQDR9","executionInfo":{"status":"ok","timestamp":1626916786896,"user_tz":420,"elapsed":291,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["VOCAB_SIZE = len(t.word_index)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iUV8IJd_QHYZ"},"source":["## LSTM Model\n","\n","## Embeddings\n","The Embedding layer helps us generate the word embeddings from scratch. This layer is also initialized with some weights and is updated based on our optimizer, similar to weights on the neuron units in other layers when the network tries to minimize the loss in each epoch. Thus, the embedding layer tries to optimize its weights such that we get the best word embeddings that will generate minimum error in the model and capture semantic similarity and relationships among words. How do we get the embeddings? Let’s say we have a review with three terms ['movie', 'was', 'good'] and a vocab_map consisting of word to index mappings for 175860 words.\n","\n","<img src=\"https://i.imgur.com/WuV47DW.png\">"]},{"cell_type":"markdown","metadata":{"id":"612ROHCeQSsQ"},"source":["## LSTM\n","LSTMs try to overcome the shortcomings of RNN models, especially with regard to handling long-term dependencies and problems that occur when the weight matrix associated with the units (neurons) become too small (leading to vanishing gradient) or too large (leading to exploding gradient). These architectures are more complex than regular deep networks and going into detailed internals and math concepts are out of the current scope, but we will try to cover the essentials here without making it math heavy\n","\n","<img src=\"https://i.imgur.com/c8qGKX8.png\">\n","\n","\n","\n","\n","---\n","\n","__The sequence of operations in the LSTM cell is briefly shown as follows.__\n","\n","<img src=\"https://i.imgur.com/uiIbDk1.png\">\n"]},{"cell_type":"markdown","metadata":{"id":"TDS11_bgQfhU"},"source":["## Build the Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eFfbbW6yQDM4","executionInfo":{"status":"ok","timestamp":1626917371071,"user_tz":420,"elapsed":4126,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"af9a6434-a3df-4b51-d930-59cdf8d5588c"},"source":["\n","EMBEDDING_DIM = 300 # dimension for dense embeddings for each token\n","LSTM_DIM = 128 # LSTM hidden state dimensionality \n","# MAX_SEQUENCE_LENGTH = 1000 # ref, value set above\n","\n","model = tf.keras.models.Sequential()\n","\n","model.add(tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, \n","                                    output_dim=EMBEDDING_DIM, \n","                                    input_length=MAX_SEQUENCE_LENGTH))\n","\n","model.add(tf.keras.layers.SpatialDropout1D(0.1))\n","\n","model.add(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=False))\n","\n","model.add(tf.keras.layers.Dense(256, activation='relu'))\n","\n","model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n","\n","model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n","              metrics=[\"accuracy\"])\n","model.summary()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 1000, 300)         52753800  \n","_________________________________________________________________\n","spatial_dropout1d (SpatialDr (None, 1000, 300)         0         \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 128)               219648    \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               33024     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 53,006,729\n","Trainable params: 53,006,729\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ru4X3v7-Qsn1"},"source":["## Train the Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mYbLqLKwQDKQ","executionInfo":{"status":"ok","timestamp":1626918031325,"user_tz":420,"elapsed":272299,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"ad46d98f-af78-4c5b-cdba-85b75078a0f6"},"source":["batch_size = 128\n","EPOCHS = 10\n","\n","es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n","                                      patience=2,\n","                                      restore_best_weights=True,\n","                                      verbose=1)\n","\n","model.fit(X_train, y_train, epochs=EPOCHS, batch_size=batch_size, \n","          callbacks=[es],\n","          shuffle=True, validation_split=0.1, verbose=1)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","247/247 [==============================] - 95s 363ms/step - loss: 0.4007 - accuracy: 0.8174 - val_loss: 0.3334 - val_accuracy: 0.8646\n","Epoch 2/10\n","247/247 [==============================] - 88s 356ms/step - loss: 0.1596 - accuracy: 0.9422 - val_loss: 0.3360 - val_accuracy: 0.8711\n","Epoch 3/10\n","247/247 [==============================] - 88s 356ms/step - loss: 0.0620 - accuracy: 0.9795 - val_loss: 0.4395 - val_accuracy: 0.8597\n","Restoring model weights from the end of the best epoch.\n","Epoch 00003: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f78e60a64d0>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"z9cJP3roQwUu"},"source":["## Evaluate Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UiB5shnXQyB_","executionInfo":{"status":"ok","timestamp":1626919973281,"user_tz":420,"elapsed":21321,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"d26d9b48-fab4-43aa-ef01-4613ec008668"},"source":["# Final evaluation of the model\n","scores = model.evaluate(X_test, y_test, verbose=1)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["469/469 [==============================] - 15s 31ms/step - loss: 0.3400 - accuracy: 0.8571\n","Accuracy: 85.71%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2da-OpUgQ0CD","executionInfo":{"status":"ok","timestamp":1626920005616,"user_tz":420,"elapsed":13927,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"2e38aebf-fb9c-4df2-8492-956d29ca2989"},"source":["predictions = model.predict_classes(X_test).ravel()\n","predictions[:10]"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 0, 1, 1, 0, 1, 0, 1, 1], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"JMxGSU0rb6Qb","executionInfo":{"status":"ok","timestamp":1626920009262,"user_tz":420,"elapsed":242,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["predictions = ['positive' if item == 1 else 'negative' for item in predictions]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":277},"id":"Ww7IvnT3Q19l","executionInfo":{"status":"ok","timestamp":1626920012473,"user_tz":420,"elapsed":732,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"4576232c-fd3d-4334-9976-fdf42a2bb725"},"source":["from sklearn.metrics import confusion_matrix, classification_report\n","\n","labels = ['negative', 'positive']\n","print(classification_report(test_sentiments, predictions))\n","pd.DataFrame(confusion_matrix(test_sentiments, predictions), index=labels, columns=labels)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    negative       0.81      0.93      0.87      7490\n","    positive       0.91      0.79      0.85      7510\n","\n","    accuracy                           0.86     15000\n","   macro avg       0.86      0.86      0.86     15000\n","weighted avg       0.86      0.86      0.86     15000\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>negative</th>\n","      <th>positive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>negative</th>\n","      <td>6935</td>\n","      <td>555</td>\n","    </tr>\n","    <tr>\n","      <th>positive</th>\n","      <td>1588</td>\n","      <td>5922</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          negative  positive\n","negative      6935       555\n","positive      1588      5922"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"PBm4gQc5RHLv"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CucSdxX0Q7lt"},"source":["# Stacked LSTM\n","\n","We are well aware of how the depth of a neural network helps it to learn complex and abstract concepts in general. Along the same lines, a stacked LSTM architecture, which has multiple layers of LSTMs stacked one after the other, has been shown to give considerable improvements. Stacked LSTMs were first presented by Graves et. al. in their work Speech Recognition with Deep Recurrent Neural Networks . They highlight the fact that depth (multiple layers of RNNs) has a greater impact on performance compared to the number of units per layer. \n","\n","Though there isn’t any theoretical proof to explain this performance gain, empirical results help us understand the impact. These enhancements can be attributed to the model’s capacity to learn complex features and even abstract representation of inputs. Since there is a time component associated with LSTMs and RNNs in general, deeper networks learn the ability to operate at different time scales as well . \n","\n","As we are making use of the high-level Keras API, we can easily extend the architecture we used in the previous section to add additional LSTM layers."]},{"cell_type":"markdown","metadata":{"id":"C2zXeeBgQ_Wd"},"source":["## Build Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uar9c-ArQ_F-","executionInfo":{"status":"ok","timestamp":1626920172360,"user_tz":420,"elapsed":832,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"b2657194-d46c-442d-9379-481b498cac93"},"source":["model2 = tf.keras.models.Sequential()\n","\n","model2.add(tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, \n","                                     output_dim=EMBEDDING_DIM, \n","                                     input_length=MAX_SEQUENCE_LENGTH))\n","model2.add(tf.keras.layers.SpatialDropout1D(0.1))\n","\n","model2.add(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=True)) # you can add more lstm layers, just set\n","# return_sequences=True for each additional lstm layer. \n","model2.add(tf.keras.layers.LSTM(LSTM_DIM, return_sequences=False)) # the last lstm layer must have\n","# return_sequences=False before passing on to the Dense layers below.\n","\n","model2.add(tf.keras.layers.Dense(256, activation='relu'))\n","model2.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n","\n","model2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n","              metrics=[\"accuracy\"])\n","model2.summary()"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 1000, 300)         52753800  \n","_________________________________________________________________\n","spatial_dropout1d_1 (Spatial (None, 1000, 300)         0         \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 1000, 128)         219648    \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 128)               131584    \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               33024     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 53,138,313\n","Trainable params: 53,138,313\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pZpPTGdZRKVZ"},"source":["## Train the Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lGWJ_NJIQ_D7","executionInfo":{"status":"ok","timestamp":1626921214574,"user_tz":420,"elapsed":286986,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"e5381ba3-ae89-432d-84e5-cf8754c1dcd2"},"source":["batch_size = 128\n","EPOCHS = 10\n","\n","es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n","                                      patience=2,\n","                                      restore_best_weights=True,\n","                                      verbose=1)\n","\n","model2.fit(X_train, y_train, epochs=EPOCHS, batch_size=batch_size, \n","           callbacks=[es],\n","           shuffle=True, validation_split=0.1, verbose=1)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","247/247 [==============================] - 98s 386ms/step - loss: 0.4395 - accuracy: 0.8024 - val_loss: 0.2946 - val_accuracy: 0.8760\n","Epoch 2/10\n","247/247 [==============================] - 94s 380ms/step - loss: 0.1899 - accuracy: 0.9314 - val_loss: 0.3131 - val_accuracy: 0.8771\n","Epoch 3/10\n","247/247 [==============================] - 94s 381ms/step - loss: 0.0694 - accuracy: 0.9780 - val_loss: 0.4008 - val_accuracy: 0.8743\n","Restoring model weights from the end of the best epoch.\n","Epoch 00003: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f78d01b3350>"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"R4PwVSsuRN0X"},"source":["## Evaluate Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0X4N5VlTQ_Aq","executionInfo":{"status":"ok","timestamp":1626921254506,"user_tz":420,"elapsed":23408,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"56ef9f94-e17a-4d1a-e440-f220cf8db7d7"},"source":["# Final evaluation of the model\n","scores = model2.evaluate(X_test, y_test, verbose=1)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["469/469 [==============================] - 23s 49ms/step - loss: 0.2928 - accuracy: 0.8773\n","Accuracy: 87.73%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7xSiW6KvQ-97","executionInfo":{"status":"ok","timestamp":1626921438603,"user_tz":420,"elapsed":21369,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"69f79fd2-bc6a-4eb1-a7ce-712e5c3e75ff"},"source":["predictions = model2.predict_classes(X_test).ravel()\n","predictions[:10]"],"execution_count":27,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 0, 1, 1, 0, 1, 0, 1, 1], dtype=int32)"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"cZ0GcEiCTDNQ"},"source":["predictions = ['positive' if item == 1 else 'negative' for item in predictions]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"CTJawGexQ9tO","outputId":"ce4b4645-3ab3-42d4-b9af-543d5f9c1bf0"},"source":["labels = ['negative', 'positive']\n","print(classification_report(test_sentiments, predictions))\n","pd.DataFrame(confusion_matrix(test_sentiments, predictions), index=labels, columns=labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    negative       0.87      0.91      0.89      7490\n","    positive       0.90      0.86      0.88      7510\n","\n","    accuracy                           0.88     15000\n","   macro avg       0.88      0.88      0.88     15000\n","weighted avg       0.88      0.88      0.88     15000\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>negative</th>\n","      <th>positive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>negative</th>\n","      <td>6785</td>\n","      <td>705</td>\n","    </tr>\n","    <tr>\n","      <th>positive</th>\n","      <td>1055</td>\n","      <td>6455</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          negative  positive\n","negative      6785       705\n","positive      1055      6455"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"62XxIdPyRTvv"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FWsAThaORUmt"},"source":["# Bidirectional LSTM\n","\n","The second variant very widely used nowadays is the bidirectional LSTM. We have already discussed how LSTMs, and RNNs in general, condition their outputs by making use of previous timesteps. When it comes to text or any sequence data, this means that the LSTM is able to make use of past context to predict future timesteps. While this is a very useful property, this is not the best we can achieve.\n","\n","A bidirectional LSTM (or biLSTM) is a combination of  two LSTM layers which work simultaneously. The first is the usual forward LSTM which takes the input sequence in its original order. The second one is called the backward LSTM which takes a reversed copy of the sequence as input. The forward and backward LSTMs work in tandem to process the original and reversed copy of the input sequences. Since we have two LSTM cells working on different contexts at any given time step, we need a way of defining the output that will be used by the downstream layers in the network. The outputs can be combined via summation, multiplication, concatenation or even averaging of hidden states. Different deep learning frameworks might set different defaults, but the most widely used method is concatenation of the biLSTM outputs\n"]},{"cell_type":"markdown","metadata":{"id":"EaWl5a8gSBTY"},"source":["## Build Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SLa5ryb4Q-fI","executionInfo":{"status":"ok","timestamp":1626921782584,"user_tz":420,"elapsed":1495,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"b9d0a42f-62a8-4c9f-b0ba-8eeebf780e1e"},"source":["EMBEDDING_DIM = 300 # dimension for dense embeddings for each token\n","LSTM_DIM = 128 # total LSTM units\n","\n","inp = tf.keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,))\n","\n","x = tf.keras.layers.Embedding(VOCAB_SIZE, \n","                              EMBEDDING_DIM, \n","                              trainable=True)(inp)\n","\n","x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_DIM, \n","                                                       return_sequences=True),\n","                                  merge_mode='concat')(x)\n","\n","x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_DIM, \n","                                                       return_sequences=False),\n","                                  merge_mode='concat')(x)\n","\n","x = tf.keras.layers.Dense(256, activation='relu')(x)\n","x = tf.keras.layers.Dropout(rate=0.2)(x)\n","x = tf.keras.layers.Dense(256, activation='relu')(x)\n","x = tf.keras.layers.Dropout(rate=0.2)(x)\n","\n","outp = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","# initialize the model\n","model3 = tf.keras.models.Model(inputs=inp, outputs=outp)\n","\n","    \n","model3.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), \n","               metrics=['accuracy'])\n","model3.summary()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 1000)]            0         \n","_________________________________________________________________\n","embedding_3 (Embedding)      (None, 1000, 300)         52753800  \n","_________________________________________________________________\n","bidirectional_2 (Bidirection (None, 1000, 256)         439296    \n","_________________________________________________________________\n","bidirectional_3 (Bidirection (None, 256)               394240    \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1)                 257       \n","=================================================================\n","Total params: 53,719,177\n","Trainable params: 53,719,177\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fGSaZzLASnBR"},"source":["## Train Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ZQvHVfsSoCe","executionInfo":{"status":"ok","timestamp":1626922171044,"user_tz":420,"elapsed":312482,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"b8510c21-8aef-4685-a152-4e7292594dc4"},"source":["batch_size = 100\n","model3.fit(X_train, y_train, epochs=2, batch_size=batch_size, \n","           shuffle=True, validation_split=0.1, verbose=1)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","315/315 [==============================] - 159s 491ms/step - loss: 0.3822 - accuracy: 0.8238 - val_loss: 0.3039 - val_accuracy: 0.8729\n","Epoch 2/2\n","315/315 [==============================] - 153s 486ms/step - loss: 0.1454 - accuracy: 0.9487 - val_loss: 0.3674 - val_accuracy: 0.8420\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f78063d7f10>"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"hlzq1VB8SqLn"},"source":["## Evaluate Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Udy8FuJSqij","executionInfo":{"status":"ok","timestamp":1626922239102,"user_tz":420,"elapsed":42560,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"9f342489-f003-4796-ba91-9cc5fca74459"},"source":["# Final evaluation of the model\n","scores = model3.evaluate(X_test, y_test, verbose=1)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["469/469 [==============================] - 42s 88ms/step - loss: 0.3715 - accuracy: 0.8361\n","Accuracy: 83.61%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vsvoMk6sSt8N","executionInfo":{"status":"ok","timestamp":1626922291142,"user_tz":420,"elapsed":41155,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"cae9fab0-1172-48bd-a6da-5e59791ccb57"},"source":["prediction_probs = model3.predict(X_test, verbose=1).ravel()\n","predictions = [1 if prob > 0.5 else 0 for prob in prediction_probs]\n","predictions[:10]"],"execution_count":32,"outputs":[{"output_type":"stream","text":["469/469 [==============================] - 41s 84ms/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0, 1, 0, 1, 1, 0, 1, 0, 1, 1]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"A-VGLDvYTEfP","executionInfo":{"status":"ok","timestamp":1626922359116,"user_tz":420,"elapsed":222,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}}},"source":["predictions = ['positive' if item == 1 else 'negative' for item in predictions]"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":277},"id":"GQ9NrzLtTHKn","executionInfo":{"status":"ok","timestamp":1626922362137,"user_tz":420,"elapsed":747,"user":{"displayName":"Fritz Zuhl","photoUrl":"","userId":"13987999814289899923"}},"outputId":"36260326-9c4f-488b-b88d-d0074aebb1e8"},"source":["labels = ['negative', 'positive']\n","print(classification_report(test_sentiments, predictions))\n","pd.DataFrame(confusion_matrix(test_sentiments, predictions), index=labels, columns=labels)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    negative       0.83      0.85      0.84      7490\n","    positive       0.85      0.82      0.83      7510\n","\n","    accuracy                           0.84     15000\n","   macro avg       0.84      0.84      0.84     15000\n","weighted avg       0.84      0.84      0.84     15000\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>negative</th>\n","      <th>positive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>negative</th>\n","      <td>6374</td>\n","      <td>1116</td>\n","    </tr>\n","    <tr>\n","      <th>positive</th>\n","      <td>1342</td>\n","      <td>6168</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          negative  positive\n","negative      6374      1116\n","positive      1342      6168"]},"metadata":{"tags":[]},"execution_count":35}]}]}